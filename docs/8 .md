# 8.期望  

> 译者：[PEGASUS1993](https://github.com/PEGASUS1993)

## 8.0 期望概述
关于概率是如何分布在变量所有可能值的，随机变量的分布给我们提供了详细信息。但是通常我们只是想大致了解它们分布在数字线的位置。换句话来说，我们只是想知道分布中心的位置。  
经历过多次“期中”考试的任何学生都知道，“中间”和“中心”这样的词语没有独特的含义。本章是关于随机变量的一种特殊“中心”。  
### 示例  
```
from datascience import *  
from prob140 import *  
import numpy as np  
import matplotlib.pyplot as plt  
plt.style.use('fivethirtyeight')  
%matplotlib inline
```
## 8.1 定义  

随机变量 X 的期望，可以表示为 E(X)，是由 X 经过概率加权所有可能值的平均值。这可以用两种等效的方式来计算。  
在 X 的域上：
  
　　　　　　　　　　　　E(X) = \sum_{\text{all }x} xP(X=x) 

在 X 的范围内：　　

　　　　　　　　　　　　E(X)=∑(all x)xP(X=x)

 
解释说明：  
如果 X 具有有限多个可能的值，则上式的总和总是很好定义并且是有限的。如果 X 是有相当多的取值，比如由 1,2,3...索引的值，那么我们需要更加小心以确保公式可以得到被明确定义的数值。我们后续将很快涉及到这个问题。现在，我们先假设总和已经被明确定义。  
假设总和定义明确，可以直接表明这两个公式会给出相同的答案。 显示它的一种方法是在所有不同的结果ω中，通过 X（ω）的不同值对第一个求和公式中的项进行分组。  
第二个公式通常作为期望的“定义”给出，但第一个公式可以有助于理解期望的特性。 特别是，它表明如果两个随机变量具有相同的分布，那么它们也应该具有相同的期望。  
### 重心
假设 X 具有以下给出的分布：  
示例：  
```
x = np.arange(1, 6)  #创建 array([1, 2, 3, 4, 5])  
probs = make_array(0.15, 0.25, 0.3, 0.2, 0.1)  
example_dist = Table().values(x).probability(probs)  
Plot(example_dist)
```


   
![](https://i.imgur.com/0L64UxZ.png)  
然后通过 X 的范围上的公式，我们得到 E（X）= 2.85。  
```
ev_X = sum(x*probs)  
ev_X
```  
2.8499999999999996  
你也可以调用 prob14 中的 ev 函数来计算期望 E(X):  
```
example_dist.ev()
```  
2.8500000000000005  
期望我们通常也成为期望值，因此不论是该函数的名称还是我们的名称 ev_V，都是可以这么称呼的。但是请注意期望值不一定是随机变量的可能值。例如该随机变量的可能值就不是 2.85.  
但那么期望值代表着什么呢？要想看到这一点，我们要使用 Plot 中的 show_ev = True 的参数，来可视化期望 E(X).  
```Plot(example_dist, show_ev=True) ``` 
![](https://i.imgur.com/nFNFMj9.png)


##  
如果你已经研究了一些物理学，你会发现我们用于期望的公式与系统的重心公式是相同的，其中权重等于从 1,2,3,4,5 这些可能值相应的概率。  
因此，假设直方图是由纸板或一些刚性材料制成，并想象试图在水平轴上某处固定的铅笔尖上找到平衡点。 你需要将铅笔保持在 2.85 才能达到平衡。  
期望可以看作是物理意义上的分布中心：它是分布的重心或质心。
### 长期平均成本曲线  
当您在相同条件下一次又一次地生成变量时，您还可以将期望视为随机变量的长期平均值。适用于 prob140 分配对象的 sample_from_dist 方法允许您这样做。它随机抽样，从分布中替换，并返回一组采样值。 参数是样本大小。  
您可以使用 emp_dist 函数将模拟值数组转换为分布对象，可以将其与 Plot 和其他 prob140 函数一起使用。 Plot 的 show_ave = True 参数可以显示模拟值的平均值。  
### 示例  
``` 
simulated_X = example_dist.sample_from_dist(10000)  
emp_dist_X = emp_dist(simulated_X)  
Plot(emp_dist_X, show_ave=True)  
plt.title('Empirical Distribution');  
```
![](https://i.imgur.com/nxIBBxW.png)  

X 的 10000 个模拟值的平均值非常接近 E(X)，但不完全相等。  


`np.mean(simulated_X) `

2.8502000000000001  

这是由于您可以在经验直方图中看到：它看起来非常像 X 的概率直方图。大约 15％的模拟值是 1，大约 20％是 2，依此类推，所以平均值非常接近 2.85。   
两个直方图的相似性是因为您在 Data8 中看到的平均定律，我们将在此课程中正式建立 。  
现在我们有几种考虑期望的方法，让我们看看为什么它具有如此重要的意义。 我们将从直接使用定义开始计算一些期望。在后续章节中，我们将开发更强大的方法来计算和使用期望。  
### 唯一性  
这个小例子值得写出来因为它一直被使用。假设随机变量 X 实际上是一个常数 c，即假设 P（X = c）= 1。 然后 X 的分布将其所有质量放在单个值 c 上，并且 E（X）=c⋅1= c。 我们只写 E（c）= c。  
###伯努利和指标  
如果 X 服从伯努利（p）分布，那么 P（X = 1）=p 和 P（X = 0）= 1-p。那么  

　　　　　　　　　　　　　　　E(X)=0⋅(1−p) + 1⋅p = p  　　
如上所述，零/一值随机变量是其他变量的构建块，它们被称为指标。  
假设 A 可以是任何事件，然后 A 的指标是随机变量 I<sub>A</sub>，如果 A 发生则为 1，如果 A 不发生则为 0。这样 I<sub>A</sub>就服从伯努利(P(A)) 分布，可以通过 E(I<sub>A</sub>)=P(A)该式计算。因此，每个概率都是一种期望。我们将在后面的部分中大量使用它。  
```
X = [0, 1]    
qp = [0.75, 0.25]    
bern_1_3 = Table().values(x).probability(qp)    
Plot(bern_1_3, show_ev=True)    
plt.title('Bernoulli (0.25)')   
```  
![](https://i.imgur.com/8JE9Jq8.png)

### 整数区间的一致性  
设 a 和 b 为两个整数，使 a <b。如果 X 在整数 a，a + 1，a + 2，...，b 上具有均匀分布，那么根据对称性，E(X)应该是在 a 和 b 中间位置的。这就是可以将概率直方图平衡的地方。所以有
　　　　　　　　　　　　　　$$ E(X) = \frac{a+b}{2} $$
例如，如果 X 在 1,2，...，n 上具有均匀分布，那么  
　　　　　　　　　　　　　　　　　　　　E(X)=(n+1)/2　　
这种情况的一个例子是，如果 X 是骰子的一个的斑点数，那么 E(X)=3.5。  

如果 X 在 0,1,2，...，n 上是均匀的，那么 E(X)=n/2。  
```
x = np.arange(10)
probs = 0.1*np.ones(10)
unif_10 = Table().values(x).probability(probs)
Plot(unif_10, show_ev=True)
plt.title('Uniform on Integers 0, 1, 2, ..., 9')
```
![](https://i.imgur.com/w0J2Qpb.png)

### 泊松分布

设 X 具有泊松分布(μ)，则  

　　　　　　　![](https://i.imgur.com/6vOMG96.png)

现在我们要对泊松分布的参数进行一个重要的新解释。我们之前看到它的接近形式，现在我们知道这也是分布的平衡点或期望，我们可以使用符号μ代表“均值”。  
```
k = np.arange(15)
poi_2_probs = stats.poisson.pmf(k, 2)
dist_poi_2 = Table().values(k).probability(poi_2_probs)
Plot(dist_poi_2, show_ev=True)
plt.title('Poisson (2)')
```
![](https://i.imgur.com/1Cn6hm9.png)
### 存在性
如果 X 有相当多的值，那么用于定义期望的总和是无限的，因此被限制为求部分和。但并非所有部分和的序列都是有限的，因此并非所有随机变量都有期望。实际上，当和是绝对收敛时，E（X）才被很好地定义：  
$$ E(X) = \sum_{\text{all }x} xP(X=x) ~~~~ \text{provided } \sum_{\text{all }x} |x|P(X=x) < \infty $$    
对于这个水平的课程来说，这有点技术性，在 Pro140 中，你几乎永远不必处理不存在的期望。请记住，期望并不总是有限的，甚至不是很明确。
这里有一个例子，你可以看到期望不能是有限的。 首先注意序列 1 / 2n，n = 1,2,3，...是概率分布，即通过对几何系列求和得到 1。  
　　　　　　![](https://i.imgur.com/8cXoicc.png)　　
现在假设随机变量Ｘ具有 2,4,8,16 ...这些值，因此对于 n=1,2,3，...，P（Ｘ=2n）= 1/ 2n。然后对于每个可能的值Ｘ，乘积 xＰ（Ｘ= x）= 1。如果你试图添加无限多的 1，唯一合理的答案是无限。　　
当分布具有“质量漂移至无穷大”的速率时，就会发生这种期望的问题，这时的速率在概率直方图水平轴方向的任何位置上无法达到平衡。  
## 8.2 可加性  
```
# HIDDEN
from datascience import *
from prob140 import *
import numpy as np
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
%matplotlib inline
import math
from scipy import stats
from scipy import misc
```
在简单的情况下，通过插入定义来计算期望可以起作用，但通常它可能很麻烦或缺乏洞察力。 可以证实，计算期望的最有力结果不是定义。它看起来相当 innocuous。  
### 可加性 
设 X 和 Y 是在相同概率空间上定义的两个随机变量，那么  
　　　　　　　　Ｅ(X+Y) = E(X) + E(Y)  
在我们更仔细地研究这个结果之前，请注意我们事先假设所有期望是存在的; 我们将在本课程中始终贯彻这个假设。  
现在注意到没有关于 X 和 Y 之间关系的假设。它们可以是相关或独立的。无论如何，总和的期望是期望的总和。 这使得结果强有力。  
从 X + Y 的定义和域空间的期望定义可以很容易地看出可加性。首先注意随机变量 X + Y 是由(X+Y)(ω)=X(ω)+Y(ω) for all ω∈Ω定义的函数。  
因此，“由概率加权的 X + Y 的值”可写为(X+Y)(ω)⋅P(ω)=X(ω)P(ω)+Y(ω)P(ω)。  
从两方面对所有ω∈Ω求和，以证明期望的可加性。  
通过归纳，可加性扩展到任何有限数量的随机变量。如果 X1，X2，...，Xn 是在相同概率空间上定义的随机变量，那么 E(X1+X2+⋯+Xn)=E(X1)+E(X2)+⋯+E(Xn)。  
如果你试图找到一个期望，那么使用可加性的方法是将随机变量写成一个简单变量的总和，这些变量的期望是你知道的或者可以很容易地计算出来的。 本节的其余部分包含此技术的示例。  
### 样本总和
设 X1，X2，...，Xn 是服从均匀分布为μ的数字总体中随机抽取的样本，并且使样本总和为 Sn=X1+X2+⋯+Xn。 然后无论是否抽取样品，每个 Xi 都具有与种群相同的分布。如果样品被抽取的话，这显然是正确的，正如我们在前面的章节中看到的那样，如果样品没有被抽取，那么就是对称的。  
因此和是否抽取样本是无关的，（待校对） E(Sn)=E(X1)+E(X2)+⋯+E(Xn)=nμ  
### 线性函数规则
设 X 为随机变量，期望为 E（X），并且对于某一常数 a，设 Y = aX。 例如，当您将随机长度的单位从英寸更改为厘米时，则 a = 2.54(注：1 英寸(in)=2.54 厘米(cm))。  
## ８.3 函数期望   
  
一旦我们开始使用随机变量作为估算器，我们将希望看到估计值与期望值的差距。例如，我们可能想要查看随机变量 X 与数字 10 的距离。这是关于 X 的函数。我们称之为 Y.那么  
Y = |X-10|  
这不是一个线性函数。为了计算 E(Y),我们还需要一点点的技巧。在整个过程中，我们将假设我们正在讨论的所有期望都已明确定义。  
本节是关于找到已知道的随机变量函数的期望。  
在下文中，设 X 是一个随机变量，其分布（因此也是期望）是已知的。  
### 线性函数规则 
对于某一常数 a 和 b，设 Y = aX + b。在前面的部分中，我们展示了这一点  
E(Y) = aE(X) + b  
这个公式包含了 a=0 的特殊情况，这样的话 Y 就是常数 b,期望就是 b。   
### 非线性函数规则
 现在，我们假设 Y= g(X),其中 g 是任何数值函数。请记住，X 是Ω上的函数。所以定义随机变量 Y 的函数是一个组合：  
![](https://i.imgur.com/gsFHGQl.png)  
这允许我们以三种等效方式书写 E(Y):    
在 Y 的范围内，在域Ω ，在 X 的范围内分别对应如下三个公式　　
                
 　　![](https://i.imgur.com/V0o9GAJ.png)   

和以前一样，这是一个直接的分组问题，表明所有形式都是等价的。      

第一种形式看起来最简单，但有一个问题：你需要先找到 P（Y = y）。第二种形式涉及不必要的高度细节。  

第三种形式是使用的形式。 它使用已知的 X 分布。它表示找到 E（Y），其中 Y = g（X）表示某些函数 g：  

取 X 的通用值 x。  

将 g 应用于 x; 这个 g（x）是 Y 的通用值。  

权重 g（x）乘以 P（X = x），这是已知的。  

为所有 x 执行此操作并累加。总和是 E（Y）。  

关于这种方法需要注意的关键是我们不必首先找到 Y 的分布。这为我们节省了大量的工作。 让我们看看我们的方法在一些例子中是如何工作的。　　　　　　　　　
　　　　

